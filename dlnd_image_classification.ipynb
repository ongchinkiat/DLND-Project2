{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Image Classification\n",
    "In this project, you'll classify images from the [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html).  The dataset consists of airplanes, dogs, cats, and other objects. You'll preprocess the images, then train a convolutional neural network on all the samples. The images need to be normalized and the labels need to be one-hot encoded.  You'll get to apply what you learned and build a convolutional, max pooling, dropout, and fully connected layers.  At the end, you'll get to see your neural network's predictions on the sample images.\n",
    "## Get the Data\n",
    "Run the following cell to download the [CIFAR-10 dataset for python](https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files found!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "import problem_unittests as tests\n",
    "import tarfile\n",
    "\n",
    "cifar10_dataset_folder_path = 'cifar-10-batches-py'\n",
    "\n",
    "# Use Floyd's cifar-10 dataset if present\n",
    "floyd_cifar10_location = '/input/cifar-10/python.tar.gz'\n",
    "if isfile(floyd_cifar10_location):\n",
    "    tar_gz_path = floyd_cifar10_location\n",
    "else:\n",
    "    tar_gz_path = 'cifar-10-python.tar.gz'\n",
    "\n",
    "class DLProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "if not isfile(tar_gz_path):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='CIFAR-10 Dataset') as pbar:\n",
    "        urlretrieve(\n",
    "            'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz',\n",
    "            tar_gz_path,\n",
    "            pbar.hook)\n",
    "\n",
    "if not isdir(cifar10_dataset_folder_path):\n",
    "    with tarfile.open(tar_gz_path) as tar:\n",
    "        tar.extractall()\n",
    "        tar.close()\n",
    "\n",
    "\n",
    "tests.test_folder_path(cifar10_dataset_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Explore the Data\n",
    "The dataset is broken into batches to prevent your machine from running out of memory.  The CIFAR-10 dataset consists of 5 batches, named `data_batch_1`, `data_batch_2`, etc.. Each batch contains the labels and images that are one of the following:\n",
    "* airplane\n",
    "* automobile\n",
    "* bird\n",
    "* cat\n",
    "* deer\n",
    "* dog\n",
    "* frog\n",
    "* horse\n",
    "* ship\n",
    "* truck\n",
    "\n",
    "Understanding a dataset is part of making predictions on the data.  Play around with the code cell below by changing the `batch_id` and `sample_id`. The `batch_id` is the id for a batch (1-5). The `sample_id` is the id for a image and label pair in the batch.\n",
    "\n",
    "Ask yourself \"What are all possible labels?\", \"What is the range of values for the image data?\", \"Are the labels in order or random?\".  Answers to questions like these will help you preprocess the data and end up with better predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stats of batch 1:\n",
      "Samples: 10000\n",
      "Label Counts: {0: 1005, 1: 974, 2: 1032, 3: 1016, 4: 999, 5: 937, 6: 1030, 7: 1001, 8: 1025, 9: 981}\n",
      "First 20 Labels: [6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6]\n",
      "\n",
      "Example of Image 5:\n",
      "Image - Min Value: 0 Max Value: 252\n",
      "Image - Shape: (32, 32, 3)\n",
      "Label - Label Id: 1 Name: automobile\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAH0CAYAAADVH+85AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc8a9f847b8>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import helper\n",
    "import numpy as np\n",
    "\n",
    "# Explore the dataset\n",
    "batch_id = 1\n",
    "sample_id = 5\n",
    "helper.display_stats(cifar10_dataset_folder_path, batch_id, sample_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Implement Preprocess Functions\n",
    "### Normalize\n",
    "In the cell below, implement the `normalize` function to take in image data, `x`, and return it as a normalized Numpy array. The values should be in the range of 0 to 1, inclusive.  The return object should be the same shape as `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def normalize(x):\n",
    "    \"\"\"\n",
    "    Normalize a list of sample image data in the range of 0 to 1\n",
    "    : x: List of image data.  The image shape is (32, 32, 3)\n",
    "    : return: Numpy array of normalize data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    maximum = np.max(x)\n",
    "    minimum = np.min(x)\n",
    "    return (x - minimum) / (maximum - minimum)\n",
    "    #return np.array(x / 255)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_normalize(normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### One-hot encode\n",
    "Just like the previous code cell, you'll be implementing a function for preprocessing.  This time, you'll implement the `one_hot_encode` function. The input, `x`, are a list of labels.  Implement the function to return the list of labels as One-Hot encoded Numpy array.  The possible values for labels are 0 to 9. The one-hot encoding function should return the same encoding for each value between each call to `one_hot_encode`.  Make sure to save the map of encodings outside the function.\n",
    "\n",
    "Hint: Don't reinvent the wheel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "labels = np.arange(10)\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "lb.fit(labels)\n",
    "    \n",
    "def one_hot_encode(x):\n",
    "    \"\"\"\n",
    "    One hot encode a list of sample labels. Return a one-hot encoded vector for each label.\n",
    "    : x: List of sample Labels\n",
    "    : return: Numpy array of one-hot encoded labels\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return lb.transform(x)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_one_hot_encode(one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Randomize Data\n",
    "As you saw from exploring the data above, the order of the samples are randomized.  It doesn't hurt to randomize it again, but you don't need to for this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Preprocess all the data and save it\n",
    "Running the code cell below will preprocess all the CIFAR-10 data and save it to file. The code below also uses 10% of the training data for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "# Preprocess Training, Validation, and Testing Data\n",
    "helper.preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Check Point\n",
    "This is your first checkpoint.  If you ever decide to come back to this notebook or have to restart the notebook, you can start from here.  The preprocessed data has been saved to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import pickle\n",
    "import problem_unittests as tests\n",
    "import helper\n",
    "\n",
    "# Load the Preprocessed Validation data\n",
    "valid_features, valid_labels = pickle.load(open('preprocess_validation.p', mode='rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Build the network\n",
    "For the neural network, you'll build each layer into a function.  Most of the code you've seen has been outside of functions. To test your code more thoroughly, we require that you put each layer in a function.  This allows us to give you better feedback and test for simple mistakes using our unittests before you submit your project.\n",
    "\n",
    ">**Note:** If you're finding it hard to dedicate enough time for this course each week, we've provided a small shortcut to this part of the project. In the next couple of problems, you'll have the option to use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages to build each layer, except the layers you build in the \"Convolutional and Max Pooling Layer\" section.  TF Layers is similar to Keras's and TFLearn's abstraction to layers, so it's easy to pickup.\n",
    "\n",
    ">However, if you would like to get the most out of this course, try to solve all the problems _without_ using anything from the TF Layers packages. You **can** still use classes from other packages that happen to have the same name as ones you find in TF Layers! For example, instead of using the TF Layers version of the `conv2d` class, [tf.layers.conv2d](https://www.tensorflow.org/api_docs/python/tf/layers/conv2d), you would want to use the TF Neural Network version of `conv2d`, [tf.nn.conv2d](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d). \n",
    "\n",
    "Let's begin!\n",
    "\n",
    "### Input\n",
    "The neural network needs to read the image data, one-hot encoded labels, and dropout keep probability. Implement the following functions\n",
    "* Implement `neural_net_image_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `image_shape` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"x\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_label_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `n_classes` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"y\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_keep_prob_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) for dropout keep probability.\n",
    " * Name the TensorFlow placeholder \"keep_prob\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "\n",
    "These names will be used at the end of the project to load your saved model.\n",
    "\n",
    "Note: `None` for shapes in TensorFlow allow for a dynamic size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Input Tests Passed.\n",
      "Label Input Tests Passed.\n",
      "Keep Prob Tests Passed.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def neural_net_image_input(image_shape):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of image input\n",
    "    : image_shape: Shape of the images\n",
    "    : return: Tensor for image input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32, shape=[None, image_shape[0], image_shape[1], image_shape[2]], name='x')\n",
    "\n",
    "\n",
    "def neural_net_label_input(n_classes):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of label input\n",
    "    : n_classes: Number of classes\n",
    "    : return: Tensor for label input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32, [None, n_classes], name='y')\n",
    "\n",
    "\n",
    "def neural_net_keep_prob_input():\n",
    "    \"\"\"\n",
    "    Return a Tensor for keep probability\n",
    "    : return: Tensor for keep probability.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32, name='keep_prob')\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tf.reset_default_graph()\n",
    "tests.test_nn_image_inputs(neural_net_image_input)\n",
    "tests.test_nn_label_inputs(neural_net_label_input)\n",
    "tests.test_nn_keep_prob_inputs(neural_net_keep_prob_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Convolution and Max Pooling Layer\n",
    "Convolution layers have a lot of success with images. For this code cell, you should implement the function `conv2d_maxpool` to apply convolution then max pooling:\n",
    "* Create the weight and bias using `conv_ksize`, `conv_num_outputs` and the shape of `x_tensor`.\n",
    "* Apply a convolution to `x_tensor` using weight and `conv_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "* Add bias\n",
    "* Add a nonlinear activation to the convolution.\n",
    "* Apply Max Pooling using `pool_ksize` and `pool_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "\n",
    "**Note:** You **can't** use [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) for **this** layer, but you can still use TensorFlow's [Neural Network](https://www.tensorflow.org/api_docs/python/tf/nn) package. You may still use the shortcut option for all the **other** layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides):\n",
    "    \"\"\"\n",
    "    Apply convolution then max pooling to x_tensor\n",
    "    :param x_tensor: TensorFlow Tensor\n",
    "    :param conv_num_outputs: Number of outputs for the convolutional layer\n",
    "    :param conv_ksize: kernal size 2-D Tuple for the convolutional layer\n",
    "    :param conv_strides: Stride 2-D Tuple for convolution\n",
    "    :param pool_ksize: kernal size 2-D Tuple for pool\n",
    "    :param pool_strides: Stride 2-D Tuple for pool\n",
    "    : return: A tensor that represents convolution and max pooling of x_tensor\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    xshape = x_tensor.get_shape()\n",
    "    #print(conv_strides)\n",
    "    weight = tf.Variable(tf.truncated_normal([int(xshape[1]),int(xshape[2]),int(xshape[3]),conv_num_outputs], dtype=tf.float32, mean=0.0,\n",
    " stddev=0.05))\n",
    "    bias = tf.Variable(tf.truncated_normal([conv_num_outputs], dtype=tf.float32, mean=0.0, stddev=0.01))\n",
    "    #bias = tf.Variable(tf.zeros([conv_num_outputs]))\n",
    "    x_tensor = tf.nn.conv2d(x_tensor, weight, strides=[1, conv_strides[0], conv_strides[1], 1], padding='SAME')\n",
    "    x_tensor = tf.nn.bias_add(x_tensor, bias)\n",
    "    x_tensor = tf.nn.relu(x_tensor)\n",
    "    x_tensor = tf.nn.max_pool(\n",
    "        x_tensor,\n",
    "        ksize=[1, pool_ksize[0], pool_ksize[1], 1],\n",
    "        strides=[1, pool_strides[0], pool_strides[1], 1],\n",
    "        padding='SAME')\n",
    "    return x_tensor\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_con_pool(conv2d_maxpool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Flatten Layer\n",
    "Implement the `flatten` function to change the dimension of `x_tensor` from a 4-D tensor to a 2-D tensor.  The output should be the shape (*Batch Size*, *Flattened Image Size*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def flatten(x_tensor):\n",
    "    \"\"\"\n",
    "    Flatten x_tensor to (Batch Size, Flattened Image Size)\n",
    "    : x_tensor: A tensor of size (Batch Size, ...), where ... are the image dimensions.\n",
    "    : return: A tensor of size (Batch Size, Flattened Image Size).\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    xshape = x_tensor.get_shape()\n",
    "    flatten_size = int(xshape[1]) * int(xshape[2]) * int(xshape[3])\n",
    "    # -1 will make it reuse 1st size\n",
    "    x_tensor = tf.reshape(x_tensor, [-1, flatten_size])\n",
    "    return x_tensor\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_flatten(flatten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Fully-Connected Layer\n",
    "Implement the `fully_conn` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def fully_conn(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a fully connected layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    xshape = x_tensor.get_shape()\n",
    "    weight_full = tf.Variable(tf.truncated_normal([int(xshape[1]), num_outputs], dtype=tf.float32, mean=0.0, stddev=0.01))\n",
    "    bias_full = tf.Variable(tf.truncated_normal([num_outputs], dtype=tf.float32, mean=0.0, stddev=0.01))\n",
    "    #bias_full = tf.Variable(tf.zeros([num_outputs]))\n",
    "    x_tensor = tf.add(tf.matmul(x_tensor, weight_full), bias_full)\n",
    "    x_tensor = tf.nn.relu(x_tensor)\n",
    "    return x_tensor\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_fully_conn(fully_conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Output Layer\n",
    "Implement the `output` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages.\n",
    "\n",
    "**Note:** Activation, softmax, or cross entropy should **not** be applied to this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def output(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a output layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    xshape = x_tensor.get_shape()\n",
    "    weight_out = tf.Variable(tf.truncated_normal([int(xshape[1]), num_outputs], dtype=tf.float32, mean=0.0, stddev=0.01))\n",
    "    bias_out = tf.Variable(tf.truncated_normal([num_outputs], dtype=tf.float32, mean=0.0, stddev=0.01))\n",
    "    x_tensor = tf.add(tf.matmul(x_tensor, weight_out), bias_out)\n",
    "   \n",
    "    return x_tensor\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_output(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Create Convolutional Model\n",
    "Implement the function `conv_net` to create a convolutional neural network model. The function takes in a batch of images, `x`, and outputs logits.  Use the layers you created above to create this model:\n",
    "\n",
    "* Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "* Apply a Flatten Layer\n",
    "* Apply 1, 2, or 3 Fully Connected Layers\n",
    "* Apply an Output Layer\n",
    "* Return the output\n",
    "* Apply [TensorFlow's Dropout](https://www.tensorflow.org/api_docs/python/tf/nn/dropout) to one or more layers in the model using `keep_prob`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Built!\n"
     ]
    }
   ],
   "source": [
    "def conv_net(x, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a convolutional neural network model\n",
    "    : x: Placeholder tensor that holds image data.\n",
    "    : keep_prob: Placeholder tensor that hold dropout keep probability.\n",
    "    : return: Tensor that represents logits\n",
    "    \"\"\"\n",
    "    # TODO: Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "    #    Play around with different number of outputs, kernel size and stride\n",
    "    # Function Definition from Above:\n",
    "    #    conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    x = conv2d_maxpool(x, 32, (7,7), (2,2), (2,2), (2,2))\n",
    "    x = conv2d_maxpool(x, 64, (5,5), (1,1), (2,2), (2,2))\n",
    "    x = conv2d_maxpool(x, 128, (3,3), (1,1), (2,2), (2,2))\n",
    "\n",
    "    #x = conv2d_maxpool(x, 16, (3,3), (1,1), (2,2), (2,2))\n",
    "    #x = conv2d_maxpool(x, 64, (3,3), (1,1), (2,2), (2,2))\n",
    "    #x = conv2d_maxpool(x, 128, (3,3), (1,1), (2,2), (2,2))\n",
    "\n",
    "\n",
    "    # TODO: Apply a Flatten Layer\n",
    "    # Function Definition from Above:\n",
    "    #   flatten(x_tensor)\n",
    "    x = flatten(x)\n",
    "    \n",
    "    \n",
    "    # TODO: Apply 1, 2, or 3 Fully Connected Layers\n",
    "    #    Play around with different number of outputs\n",
    "    # Function Definition from Above:\n",
    "    #   fully_conn(x_tensor, num_outputs)\n",
    "    x = fully_conn(x, 600)\n",
    "    x = tf.nn.dropout(x, keep_prob)\n",
    "    x = fully_conn(x, 400)\n",
    "    x = tf.nn.dropout(x, keep_prob)\n",
    "    x = fully_conn(x, 300)\n",
    "    \n",
    "    # TODO: Apply an Output Layer\n",
    "    #    Set this to the number of classes\n",
    "    # Function Definition from Above:\n",
    "    #   output(x_tensor, num_outputs)\n",
    "    out = output(x, 10)\n",
    "    \n",
    "    \n",
    "    # TODO: return output\n",
    "    return out\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "\n",
    "##############################\n",
    "## Build the Neural Network ##\n",
    "##############################\n",
    "\n",
    "# Remove previous weights, bias, inputs, etc..\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "x = neural_net_image_input((32, 32, 3))\n",
    "y = neural_net_label_input(10)\n",
    "keep_prob = neural_net_keep_prob_input()\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, keep_prob)\n",
    "\n",
    "# Name logits Tensor, so that is can be loaded from disk after training\n",
    "logits = tf.identity(logits, name='logits')\n",
    "\n",
    "# Loss and Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "\n",
    "tests.test_conv_net(conv_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Train the Neural Network\n",
    "### Single Optimization\n",
    "Implement the function `train_neural_network` to do a single optimization.  The optimization should use `optimizer` to optimize in `session` with a `feed_dict` of the following:\n",
    "* `x` for image input\n",
    "* `y` for labels\n",
    "* `keep_prob` for keep probability for dropout\n",
    "\n",
    "This function will be called for each batch, so `tf.global_variables_initializer()` has already been called.\n",
    "\n",
    "Note: Nothing needs to be returned. This function is only optimizing the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def train_neural_network(session, optimizer, keep_probability, feature_batch, label_batch):\n",
    "    \"\"\"\n",
    "    Optimize the session on a batch of images and labels\n",
    "    : session: Current TensorFlow session\n",
    "    : optimizer: TensorFlow optimizer function\n",
    "    : keep_probability: keep probability\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    session.run(optimizer, feed_dict={\n",
    "                x: feature_batch,\n",
    "                y: label_batch,\n",
    "                keep_prob: keep_probability})\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_train_nn(train_neural_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Show Stats\n",
    "Implement the function `print_stats` to print loss and validation accuracy.  Use the global variables `valid_features` and `valid_labels` to calculate validation accuracy.  Use a keep probability of `1.0` to calculate the loss and validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
    "    \"\"\"\n",
    "    Print information about loss and validation accuracy\n",
    "    : session: Current TensorFlow session\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    : cost: TensorFlow cost function\n",
    "    : accuracy: TensorFlow accuracy function\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    loss = session.run(cost, feed_dict={\n",
    "                x: feature_batch,\n",
    "                y: label_batch,\n",
    "                keep_prob: 1.0})\n",
    "    full_accuracy = session.run(accuracy, feed_dict={\n",
    "                x: valid_features,\n",
    "                y: valid_labels,\n",
    "                keep_prob: 1.0})\n",
    "    train_accuracy = session.run(accuracy, feed_dict={\n",
    "                x: feature_batch,\n",
    "                y: label_batch,\n",
    "                keep_prob: 1.0})\n",
    "    print('Loss: {:>10.4f} Validation Accuracy: {:.6f} Train Accuracy: {:.6f}'.format(loss, full_accuracy, train_accuracy))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Hyperparameters\n",
    "Tune the following parameters:\n",
    "* Set `epochs` to the number of iterations until the network stops learning or start overfitting\n",
    "* Set `batch_size` to the highest number that your machine has memory for.  Most people set them to common sizes of memory:\n",
    " * 64\n",
    " * 128\n",
    " * 256\n",
    " * ...\n",
    "* Set `keep_probability` to the probability of keeping a node using dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# TODO: Tune Parameters\n",
    "epochs = 50\n",
    "batch_size = 256\n",
    "keep_probability = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Train on a Single CIFAR-10 Batch\n",
    "Instead of training the neural network on all the CIFAR-10 batches of data, let's use a single batch. This should save time while you iterate on the model to get a better accuracy.  Once the final validation accuracy is 50% or greater, run the model on all the data in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the Training on a Single Batch...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Loss:     2.2605 Validation Accuracy: 0.142400 Train Accuracy: 0.175000\n",
      "Epoch  2, CIFAR-10 Batch 1:  Loss:     2.1988 Validation Accuracy: 0.182400 Train Accuracy: 0.200000\n",
      "Epoch  3, CIFAR-10 Batch 1:  Loss:     2.0884 Validation Accuracy: 0.202200 Train Accuracy: 0.225000\n",
      "Epoch  4, CIFAR-10 Batch 1:  Loss:     2.0037 Validation Accuracy: 0.214800 Train Accuracy: 0.225000\n",
      "Epoch  5, CIFAR-10 Batch 1:  Loss:     1.8598 Validation Accuracy: 0.263800 Train Accuracy: 0.275000\n",
      "Epoch  6, CIFAR-10 Batch 1:  Loss:     1.7270 Validation Accuracy: 0.294400 Train Accuracy: 0.325000\n",
      "Epoch  7, CIFAR-10 Batch 1:  Loss:     1.6011 Validation Accuracy: 0.314400 Train Accuracy: 0.375000\n",
      "Epoch  8, CIFAR-10 Batch 1:  Loss:     1.4704 Validation Accuracy: 0.336400 Train Accuracy: 0.450000\n",
      "Epoch  9, CIFAR-10 Batch 1:  Loss:     1.3174 Validation Accuracy: 0.331200 Train Accuracy: 0.475000\n",
      "Epoch 10, CIFAR-10 Batch 1:  Loss:     1.1741 Validation Accuracy: 0.357800 Train Accuracy: 0.575000\n",
      "Epoch 11, CIFAR-10 Batch 1:  Loss:     1.0421 Validation Accuracy: 0.359400 Train Accuracy: 0.600000\n",
      "Epoch 12, CIFAR-10 Batch 1:  Loss:     1.1155 Validation Accuracy: 0.344400 Train Accuracy: 0.675000\n",
      "Epoch 13, CIFAR-10 Batch 1:  Loss:     0.8777 Validation Accuracy: 0.376600 Train Accuracy: 0.750000\n",
      "Epoch 14, CIFAR-10 Batch 1:  Loss:     0.9107 Validation Accuracy: 0.373400 Train Accuracy: 0.650000\n",
      "Epoch 15, CIFAR-10 Batch 1:  Loss:     0.7796 Validation Accuracy: 0.369800 Train Accuracy: 0.775000\n",
      "Epoch 16, CIFAR-10 Batch 1:  Loss:     0.7138 Validation Accuracy: 0.405200 Train Accuracy: 0.750000\n",
      "Epoch 17, CIFAR-10 Batch 1:  Loss:     0.7500 Validation Accuracy: 0.364200 Train Accuracy: 0.700000\n",
      "Epoch 18, CIFAR-10 Batch 1:  Loss:     0.6133 Validation Accuracy: 0.409600 Train Accuracy: 0.750000\n",
      "Epoch 19, CIFAR-10 Batch 1:  Loss:     0.5898 Validation Accuracy: 0.397800 Train Accuracy: 0.825000\n",
      "Epoch 20, CIFAR-10 Batch 1:  Loss:     0.4438 Validation Accuracy: 0.410000 Train Accuracy: 0.875000\n",
      "Epoch 21, CIFAR-10 Batch 1:  Loss:     0.4035 Validation Accuracy: 0.392600 Train Accuracy: 0.875000\n",
      "Epoch 22, CIFAR-10 Batch 1:  Loss:     0.3449 Validation Accuracy: 0.424800 Train Accuracy: 0.950000\n",
      "Epoch 23, CIFAR-10 Batch 1:  Loss:     0.3298 Validation Accuracy: 0.386400 Train Accuracy: 0.925000\n",
      "Epoch 24, CIFAR-10 Batch 1:  Loss:     0.3485 Validation Accuracy: 0.399200 Train Accuracy: 0.900000\n",
      "Epoch 25, CIFAR-10 Batch 1:  Loss:     0.3617 Validation Accuracy: 0.412600 Train Accuracy: 0.800000\n",
      "Epoch 26, CIFAR-10 Batch 1:  Loss:     0.3012 Validation Accuracy: 0.405600 Train Accuracy: 0.875000\n",
      "Epoch 27, CIFAR-10 Batch 1:  Loss:     0.2590 Validation Accuracy: 0.418800 Train Accuracy: 0.975000\n",
      "Epoch 28, CIFAR-10 Batch 1:  Loss:     0.2658 Validation Accuracy: 0.417600 Train Accuracy: 0.925000\n",
      "Epoch 29, CIFAR-10 Batch 1:  Loss:     0.2541 Validation Accuracy: 0.407800 Train Accuracy: 0.975000\n",
      "Epoch 30, CIFAR-10 Batch 1:  Loss:     0.2679 Validation Accuracy: 0.401400 Train Accuracy: 0.950000\n",
      "Epoch 31, CIFAR-10 Batch 1:  Loss:     0.1713 Validation Accuracy: 0.404600 Train Accuracy: 0.975000\n",
      "Epoch 32, CIFAR-10 Batch 1:  Loss:     0.1217 Validation Accuracy: 0.419200 Train Accuracy: 0.975000\n",
      "Epoch 33, CIFAR-10 Batch 1:  Loss:     0.1033 Validation Accuracy: 0.424400 Train Accuracy: 1.000000\n",
      "Epoch 34, CIFAR-10 Batch 1:  Loss:     0.0717 Validation Accuracy: 0.419600 Train Accuracy: 1.000000\n",
      "Epoch 35, CIFAR-10 Batch 1:  Loss:     0.0838 Validation Accuracy: 0.408400 Train Accuracy: 1.000000\n",
      "Epoch 36, CIFAR-10 Batch 1:  Loss:     0.0824 Validation Accuracy: 0.410400 Train Accuracy: 1.000000\n",
      "Epoch 37, CIFAR-10 Batch 1:  Loss:     0.1063 Validation Accuracy: 0.409600 Train Accuracy: 0.975000\n",
      "Epoch 38, CIFAR-10 Batch 1:  Loss:     0.0773 Validation Accuracy: 0.424200 Train Accuracy: 1.000000\n",
      "Epoch 39, CIFAR-10 Batch 1:  Loss:     0.0637 Validation Accuracy: 0.405600 Train Accuracy: 1.000000\n",
      "Epoch 40, CIFAR-10 Batch 1:  Loss:     0.0859 Validation Accuracy: 0.412400 Train Accuracy: 1.000000\n",
      "Epoch 41, CIFAR-10 Batch 1:  Loss:     0.0987 Validation Accuracy: 0.410000 Train Accuracy: 0.975000\n",
      "Epoch 42, CIFAR-10 Batch 1:  Loss:     0.0861 Validation Accuracy: 0.420200 Train Accuracy: 0.975000\n",
      "Epoch 43, CIFAR-10 Batch 1:  Loss:     0.0746 Validation Accuracy: 0.415200 Train Accuracy: 0.975000\n",
      "Epoch 44, CIFAR-10 Batch 1:  Loss:     0.0817 Validation Accuracy: 0.426600 Train Accuracy: 1.000000\n",
      "Epoch 45, CIFAR-10 Batch 1:  Loss:     0.0663 Validation Accuracy: 0.406600 Train Accuracy: 1.000000\n",
      "Epoch 46, CIFAR-10 Batch 1:  Loss:     0.0172 Validation Accuracy: 0.426400 Train Accuracy: 1.000000\n",
      "Epoch 47, CIFAR-10 Batch 1:  Loss:     0.0220 Validation Accuracy: 0.424000 Train Accuracy: 1.000000\n",
      "Epoch 48, CIFAR-10 Batch 1:  Loss:     0.0173 Validation Accuracy: 0.423600 Train Accuracy: 1.000000\n",
      "Epoch 49, CIFAR-10 Batch 1:  Loss:     0.0385 Validation Accuracy: 0.435000 Train Accuracy: 1.000000\n",
      "Epoch 50, CIFAR-10 Batch 1:  Loss:     0.0612 Validation Accuracy: 0.431200 Train Accuracy: 0.975000\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "print('Checking the Training on a Single Batch...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        start_time = time.time()\n",
    "        batch_count = 1\n",
    "        total_batch = math.ceil(10000 / batch_size)\n",
    "        batch_i = 1\n",
    "        for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "            batch_start_time = time.time()\n",
    "            train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "            batch_time = time.time() - batch_start_time\n",
    "            exp_min = batch_time * total_batch / 60\n",
    "            remain_min = (total_batch - batch_count + 1) * batch_time / 60\n",
    "            #print('Batch %d of %d Batch Time: %.3f sec. Expected Epoch Time: %.3f min. Left: %.3f min   ' % (batch_count, total_batch, batch_time, exp_min, remain_min), end='\\r')\n",
    "            batch_count += 1\n",
    "        #print('                                                                                          ', end='\\r')\n",
    "        print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "        train_time = time.time() - start_time\n",
    "        print_stats(sess, batch_features, batch_labels, cost, accuracy)\n",
    "        total_time = time.time() - start_time\n",
    "        stats_time = total_time - train_time\n",
    "        #print('Train time: %.3f, Stats Time: %.3f, Total Time: %.3f' % (train_time/60, stats_time/60, total_time/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Fully Train the Model\n",
    "Now that you got a good accuracy with a single CIFAR-10 batch, try it with all five batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Loss:     2.2135 Validation Accuracy: 0.174200 Train Accuracy: 0.150000\n",
      "Epoch  1, CIFAR-10 Batch 2:  Loss:     2.1192 Validation Accuracy: 0.166200 Train Accuracy: 0.250000\n",
      "Epoch  1, CIFAR-10 Batch 3:  Loss:     1.8426 Validation Accuracy: 0.168400 Train Accuracy: 0.250000\n",
      "Epoch  1, CIFAR-10 Batch 4:  Loss:     1.9494 Validation Accuracy: 0.181400 Train Accuracy: 0.175000\n",
      "Epoch  1, CIFAR-10 Batch 5:  Loss:     1.9102 Validation Accuracy: 0.185600 Train Accuracy: 0.225000\n",
      "Epoch  2, CIFAR-10 Batch 1:  Loss:     2.0823 Validation Accuracy: 0.237400 Train Accuracy: 0.200000\n",
      "Epoch  2, CIFAR-10 Batch 2:  Loss:     1.9122 Validation Accuracy: 0.255600 Train Accuracy: 0.275000\n",
      "Epoch  2, CIFAR-10 Batch 3:  Loss:     1.6294 Validation Accuracy: 0.250400 Train Accuracy: 0.375000\n",
      "Epoch  2, CIFAR-10 Batch 4:  Loss:     1.6715 Validation Accuracy: 0.311600 Train Accuracy: 0.375000\n",
      "Epoch  2, CIFAR-10 Batch 5:  Loss:     1.6087 Validation Accuracy: 0.326200 Train Accuracy: 0.350000\n",
      "Epoch  3, CIFAR-10 Batch 1:  Loss:     1.8433 Validation Accuracy: 0.326800 Train Accuracy: 0.300000\n",
      "Epoch  3, CIFAR-10 Batch 2:  Loss:     1.7350 Validation Accuracy: 0.342000 Train Accuracy: 0.325000\n",
      "Epoch  3, CIFAR-10 Batch 3:  Loss:     1.3939 Validation Accuracy: 0.372000 Train Accuracy: 0.500000\n",
      "Epoch  3, CIFAR-10 Batch 4:  Loss:     1.5545 Validation Accuracy: 0.370400 Train Accuracy: 0.425000\n",
      "Epoch  3, CIFAR-10 Batch 5:  Loss:     1.5454 Validation Accuracy: 0.402400 Train Accuracy: 0.425000\n",
      "Epoch  4, CIFAR-10 Batch 1:  Loss:     1.7094 Validation Accuracy: 0.397200 Train Accuracy: 0.400000\n",
      "Epoch  4, CIFAR-10 Batch 2:  Loss:     1.6130 Validation Accuracy: 0.403400 Train Accuracy: 0.375000\n",
      "Epoch  4, CIFAR-10 Batch 3:  Loss:     1.2978 Validation Accuracy: 0.420800 Train Accuracy: 0.550000\n",
      "Epoch  4, CIFAR-10 Batch 4:  Loss:     1.3082 Validation Accuracy: 0.436400 Train Accuracy: 0.500000\n",
      "Epoch  4, CIFAR-10 Batch 5:  Loss:     1.4074 Validation Accuracy: 0.439200 Train Accuracy: 0.500000\n",
      "Epoch  5, CIFAR-10 Batch 1:  Loss:     1.4804 Validation Accuracy: 0.426200 Train Accuracy: 0.550000\n",
      "Epoch  5, CIFAR-10 Batch 2:  Loss:     1.3187 Validation Accuracy: 0.419200 Train Accuracy: 0.525000\n",
      "Epoch  5, CIFAR-10 Batch 3:  Loss:     1.0208 Validation Accuracy: 0.448400 Train Accuracy: 0.650000\n",
      "Epoch  5, CIFAR-10 Batch 4:  Loss:     1.1807 Validation Accuracy: 0.455000 Train Accuracy: 0.525000\n",
      "Epoch  5, CIFAR-10 Batch 5:  Loss:     1.2307 Validation Accuracy: 0.445400 Train Accuracy: 0.525000\n",
      "Epoch  6, CIFAR-10 Batch 1:  Loss:     1.3129 Validation Accuracy: 0.451200 Train Accuracy: 0.550000\n",
      "Epoch  6, CIFAR-10 Batch 2:  Loss:     1.0941 Validation Accuracy: 0.456200 Train Accuracy: 0.625000\n",
      "Epoch  6, CIFAR-10 Batch 3:  Loss:     0.9377 Validation Accuracy: 0.469400 Train Accuracy: 0.650000\n",
      "Epoch  6, CIFAR-10 Batch 4:  Loss:     0.9606 Validation Accuracy: 0.469000 Train Accuracy: 0.650000\n",
      "Epoch  6, CIFAR-10 Batch 5:  Loss:     1.0043 Validation Accuracy: 0.471600 Train Accuracy: 0.700000\n",
      "Epoch  7, CIFAR-10 Batch 1:  Loss:     1.0857 Validation Accuracy: 0.475000 Train Accuracy: 0.650000\n",
      "Epoch  7, CIFAR-10 Batch 2:  Loss:     0.8426 Validation Accuracy: 0.478400 Train Accuracy: 0.750000\n",
      "Epoch  7, CIFAR-10 Batch 3:  Loss:     0.8004 Validation Accuracy: 0.477000 Train Accuracy: 0.700000\n",
      "Epoch  7, CIFAR-10 Batch 4:  Loss:     0.8792 Validation Accuracy: 0.472800 Train Accuracy: 0.725000\n",
      "Epoch  7, CIFAR-10 Batch 5:  Loss:     0.9480 Validation Accuracy: 0.473400 Train Accuracy: 0.700000\n",
      "Epoch  8, CIFAR-10 Batch 1:  Loss:     0.9430 Validation Accuracy: 0.492200 Train Accuracy: 0.675000\n",
      "Epoch  8, CIFAR-10 Batch 2:  Loss:     0.8099 Validation Accuracy: 0.461800 Train Accuracy: 0.800000\n",
      "Epoch  8, CIFAR-10 Batch 3:  Loss:     0.6559 Validation Accuracy: 0.475800 Train Accuracy: 0.875000\n",
      "Epoch  8, CIFAR-10 Batch 4:  Loss:     0.7755 Validation Accuracy: 0.496000 Train Accuracy: 0.725000\n",
      "Epoch  8, CIFAR-10 Batch 5:  Loss:     0.7897 Validation Accuracy: 0.492800 Train Accuracy: 0.775000\n",
      "Epoch  9, CIFAR-10 Batch 1:  Loss:     0.9140 Validation Accuracy: 0.493200 Train Accuracy: 0.700000\n",
      "Epoch  9, CIFAR-10 Batch 2:  Loss:     0.6351 Validation Accuracy: 0.477200 Train Accuracy: 0.825000\n",
      "Epoch  9, CIFAR-10 Batch 3:  Loss:     0.5490 Validation Accuracy: 0.492200 Train Accuracy: 0.875000\n",
      "Epoch  9, CIFAR-10 Batch 4:  Loss:     0.7002 Validation Accuracy: 0.504600 Train Accuracy: 0.725000\n",
      "Epoch  9, CIFAR-10 Batch 5:  Loss:     0.6460 Validation Accuracy: 0.512800 Train Accuracy: 0.825000\n",
      "Epoch 10, CIFAR-10 Batch 1:  Loss:     0.8010 Validation Accuracy: 0.513200 Train Accuracy: 0.700000\n",
      "Epoch 10, CIFAR-10 Batch 2:  Loss:     0.5401 Validation Accuracy: 0.483400 Train Accuracy: 0.875000\n",
      "Epoch 10, CIFAR-10 Batch 3:  Loss:     0.4817 Validation Accuracy: 0.490600 Train Accuracy: 0.875000\n",
      "Epoch 10, CIFAR-10 Batch 4:  Loss:     0.6564 Validation Accuracy: 0.496400 Train Accuracy: 0.825000\n",
      "Epoch 10, CIFAR-10 Batch 5:  Loss:     0.5946 Validation Accuracy: 0.510000 Train Accuracy: 0.850000\n",
      "Epoch 11, CIFAR-10 Batch 1:  Loss:     0.6772 Validation Accuracy: 0.508200 Train Accuracy: 0.700000\n",
      "Epoch 11, CIFAR-10 Batch 2:  Loss:     0.4938 Validation Accuracy: 0.513200 Train Accuracy: 0.900000\n",
      "Epoch 11, CIFAR-10 Batch 3:  Loss:     0.4730 Validation Accuracy: 0.506600 Train Accuracy: 0.875000\n",
      "Epoch 11, CIFAR-10 Batch 4:  Loss:     0.6435 Validation Accuracy: 0.489200 Train Accuracy: 0.850000\n",
      "Epoch 11, CIFAR-10 Batch 5:  Loss:     0.4924 Validation Accuracy: 0.515000 Train Accuracy: 0.850000\n",
      "Epoch 12, CIFAR-10 Batch 1:  Loss:     0.7299 Validation Accuracy: 0.500600 Train Accuracy: 0.725000\n",
      "Epoch 12, CIFAR-10 Batch 2:  Loss:     0.4771 Validation Accuracy: 0.489800 Train Accuracy: 0.900000\n",
      "Epoch 12, CIFAR-10 Batch 3:  Loss:     0.4244 Validation Accuracy: 0.506200 Train Accuracy: 0.900000\n",
      "Epoch 12, CIFAR-10 Batch 4:  Loss:     0.5230 Validation Accuracy: 0.499800 Train Accuracy: 0.875000\n",
      "Epoch 12, CIFAR-10 Batch 5:  Loss:     0.5648 Validation Accuracy: 0.492200 Train Accuracy: 0.900000\n",
      "Epoch 13, CIFAR-10 Batch 1:  Loss:     0.6521 Validation Accuracy: 0.483400 Train Accuracy: 0.850000\n",
      "Epoch 13, CIFAR-10 Batch 2:  Loss:     0.4999 Validation Accuracy: 0.508400 Train Accuracy: 0.850000\n",
      "Epoch 13, CIFAR-10 Batch 3:  Loss:     0.3247 Validation Accuracy: 0.515800 Train Accuracy: 0.900000\n",
      "Epoch 13, CIFAR-10 Batch 4:  Loss:     0.4783 Validation Accuracy: 0.504800 Train Accuracy: 0.925000\n",
      "Epoch 13, CIFAR-10 Batch 5:  Loss:     0.4051 Validation Accuracy: 0.496000 Train Accuracy: 0.950000\n",
      "Epoch 14, CIFAR-10 Batch 1:  Loss:     0.5691 Validation Accuracy: 0.493000 Train Accuracy: 0.775000\n",
      "Epoch 14, CIFAR-10 Batch 2:  Loss:     0.4740 Validation Accuracy: 0.498200 Train Accuracy: 0.900000\n",
      "Epoch 14, CIFAR-10 Batch 3:  Loss:     0.4086 Validation Accuracy: 0.514200 Train Accuracy: 0.925000\n",
      "Epoch 14, CIFAR-10 Batch 4:  Loss:     0.3694 Validation Accuracy: 0.513400 Train Accuracy: 0.900000\n",
      "Epoch 14, CIFAR-10 Batch 5:  Loss:     0.3079 Validation Accuracy: 0.514000 Train Accuracy: 0.950000\n",
      "Epoch 15, CIFAR-10 Batch 1:  Loss:     0.4838 Validation Accuracy: 0.507000 Train Accuracy: 0.875000\n",
      "Epoch 15, CIFAR-10 Batch 2:  Loss:     0.4066 Validation Accuracy: 0.511000 Train Accuracy: 0.875000\n",
      "Epoch 15, CIFAR-10 Batch 3:  Loss:     0.3273 Validation Accuracy: 0.510800 Train Accuracy: 0.950000\n",
      "Epoch 15, CIFAR-10 Batch 4:  Loss:     0.3225 Validation Accuracy: 0.520800 Train Accuracy: 0.925000\n",
      "Epoch 15, CIFAR-10 Batch 5:  Loss:     0.3351 Validation Accuracy: 0.504800 Train Accuracy: 0.975000\n",
      "Epoch 16, CIFAR-10 Batch 1:  Loss:     0.4482 Validation Accuracy: 0.489000 Train Accuracy: 0.900000\n",
      "Epoch 16, CIFAR-10 Batch 2:  Loss:     0.3488 Validation Accuracy: 0.518400 Train Accuracy: 0.900000\n",
      "Epoch 16, CIFAR-10 Batch 3:  Loss:     0.2933 Validation Accuracy: 0.505000 Train Accuracy: 0.950000\n",
      "Epoch 16, CIFAR-10 Batch 4:  Loss:     0.3600 Validation Accuracy: 0.510400 Train Accuracy: 0.900000\n",
      "Epoch 16, CIFAR-10 Batch 5:  Loss:     0.2893 Validation Accuracy: 0.503600 Train Accuracy: 0.925000\n",
      "Epoch 17, CIFAR-10 Batch 1:  Loss:     0.3608 Validation Accuracy: 0.500600 Train Accuracy: 0.925000\n",
      "Epoch 17, CIFAR-10 Batch 2:  Loss:     0.3469 Validation Accuracy: 0.515000 Train Accuracy: 0.925000\n",
      "Epoch 17, CIFAR-10 Batch 3:  Loss:     0.2774 Validation Accuracy: 0.492200 Train Accuracy: 0.975000\n",
      "Epoch 17, CIFAR-10 Batch 4:  Loss:     0.3375 Validation Accuracy: 0.514400 Train Accuracy: 0.925000\n",
      "Epoch 17, CIFAR-10 Batch 5:  Loss:     0.2091 Validation Accuracy: 0.505800 Train Accuracy: 0.950000\n",
      "Epoch 18, CIFAR-10 Batch 1:  Loss:     0.3975 Validation Accuracy: 0.505600 Train Accuracy: 0.875000\n",
      "Epoch 18, CIFAR-10 Batch 2:  Loss:     0.3756 Validation Accuracy: 0.512200 Train Accuracy: 0.925000\n",
      "Epoch 18, CIFAR-10 Batch 3:  Loss:     0.2674 Validation Accuracy: 0.502000 Train Accuracy: 0.925000\n",
      "Epoch 18, CIFAR-10 Batch 4:  Loss:     0.3243 Validation Accuracy: 0.505600 Train Accuracy: 0.950000\n",
      "Epoch 18, CIFAR-10 Batch 5:  Loss:     0.1748 Validation Accuracy: 0.500000 Train Accuracy: 0.950000\n",
      "Epoch 19, CIFAR-10 Batch 1:  Loss:     0.3361 Validation Accuracy: 0.507000 Train Accuracy: 0.950000\n",
      "Epoch 19, CIFAR-10 Batch 2:  Loss:     0.3338 Validation Accuracy: 0.520600 Train Accuracy: 0.950000\n",
      "Epoch 19, CIFAR-10 Batch 3:  Loss:     0.2054 Validation Accuracy: 0.512400 Train Accuracy: 1.000000\n",
      "Epoch 19, CIFAR-10 Batch 4:  Loss:     0.3083 Validation Accuracy: 0.499400 Train Accuracy: 0.975000\n",
      "Epoch 19, CIFAR-10 Batch 5:  Loss:     0.1915 Validation Accuracy: 0.512000 Train Accuracy: 0.975000\n",
      "Epoch 20, CIFAR-10 Batch 1:  Loss:     0.4400 Validation Accuracy: 0.505200 Train Accuracy: 0.800000\n",
      "Epoch 20, CIFAR-10 Batch 2:  Loss:     0.2696 Validation Accuracy: 0.518800 Train Accuracy: 0.975000\n",
      "Epoch 20, CIFAR-10 Batch 3:  Loss:     0.2158 Validation Accuracy: 0.494200 Train Accuracy: 1.000000\n",
      "Epoch 20, CIFAR-10 Batch 4:  Loss:     0.2410 Validation Accuracy: 0.501000 Train Accuracy: 0.975000\n",
      "Epoch 20, CIFAR-10 Batch 5:  Loss:     0.1891 Validation Accuracy: 0.495800 Train Accuracy: 1.000000\n",
      "Epoch 21, CIFAR-10 Batch 1:  Loss:     0.3502 Validation Accuracy: 0.516800 Train Accuracy: 0.875000\n",
      "Epoch 21, CIFAR-10 Batch 2:  Loss:     0.2052 Validation Accuracy: 0.509000 Train Accuracy: 0.975000\n",
      "Epoch 21, CIFAR-10 Batch 3:  Loss:     0.1996 Validation Accuracy: 0.496200 Train Accuracy: 0.975000\n",
      "Epoch 21, CIFAR-10 Batch 4:  Loss:     0.2041 Validation Accuracy: 0.515200 Train Accuracy: 0.975000\n",
      "Epoch 21, CIFAR-10 Batch 5:  Loss:     0.1532 Validation Accuracy: 0.508200 Train Accuracy: 1.000000\n",
      "Epoch 22, CIFAR-10 Batch 1:  Loss:     0.3196 Validation Accuracy: 0.514400 Train Accuracy: 0.900000\n",
      "Epoch 22, CIFAR-10 Batch 2:  Loss:     0.2360 Validation Accuracy: 0.505800 Train Accuracy: 0.950000\n",
      "Epoch 22, CIFAR-10 Batch 3:  Loss:     0.1346 Validation Accuracy: 0.497000 Train Accuracy: 0.975000\n",
      "Epoch 22, CIFAR-10 Batch 4:  Loss:     0.2498 Validation Accuracy: 0.507400 Train Accuracy: 1.000000\n",
      "Epoch 22, CIFAR-10 Batch 5:  Loss:     0.2050 Validation Accuracy: 0.490200 Train Accuracy: 0.975000\n",
      "Epoch 23, CIFAR-10 Batch 1:  Loss:     0.3183 Validation Accuracy: 0.493000 Train Accuracy: 0.925000\n",
      "Epoch 23, CIFAR-10 Batch 2:  Loss:     0.2784 Validation Accuracy: 0.506800 Train Accuracy: 0.925000\n",
      "Epoch 23, CIFAR-10 Batch 3:  Loss:     0.1505 Validation Accuracy: 0.517000 Train Accuracy: 0.975000\n",
      "Epoch 23, CIFAR-10 Batch 4:  Loss:     0.2289 Validation Accuracy: 0.502000 Train Accuracy: 0.975000\n",
      "Epoch 23, CIFAR-10 Batch 5:  Loss:     0.1689 Validation Accuracy: 0.494000 Train Accuracy: 1.000000\n",
      "Epoch 24, CIFAR-10 Batch 1:  Loss:     0.3486 Validation Accuracy: 0.510000 Train Accuracy: 0.900000\n",
      "Epoch 24, CIFAR-10 Batch 2:  Loss:     0.2308 Validation Accuracy: 0.505400 Train Accuracy: 0.975000\n",
      "Epoch 24, CIFAR-10 Batch 3:  Loss:     0.1503 Validation Accuracy: 0.511200 Train Accuracy: 1.000000\n",
      "Epoch 24, CIFAR-10 Batch 4:  Loss:     0.2199 Validation Accuracy: 0.514400 Train Accuracy: 0.975000\n",
      "Epoch 24, CIFAR-10 Batch 5:  Loss:     0.1254 Validation Accuracy: 0.505600 Train Accuracy: 1.000000\n",
      "Epoch 25, CIFAR-10 Batch 1:  Loss:     0.3013 Validation Accuracy: 0.509000 Train Accuracy: 0.925000\n",
      "Epoch 25, CIFAR-10 Batch 2:  Loss:     0.2130 Validation Accuracy: 0.516200 Train Accuracy: 0.975000\n",
      "Epoch 25, CIFAR-10 Batch 3:  Loss:     0.1227 Validation Accuracy: 0.502600 Train Accuracy: 1.000000\n",
      "Epoch 25, CIFAR-10 Batch 4:  Loss:     0.1737 Validation Accuracy: 0.510800 Train Accuracy: 0.975000\n",
      "Epoch 25, CIFAR-10 Batch 5:  Loss:     0.1015 Validation Accuracy: 0.508800 Train Accuracy: 1.000000\n",
      "Epoch 26, CIFAR-10 Batch 1:  Loss:     0.2764 Validation Accuracy: 0.499000 Train Accuracy: 0.925000\n",
      "Epoch 26, CIFAR-10 Batch 2:  Loss:     0.2054 Validation Accuracy: 0.503800 Train Accuracy: 0.950000\n",
      "Epoch 26, CIFAR-10 Batch 3:  Loss:     0.0888 Validation Accuracy: 0.503400 Train Accuracy: 1.000000\n",
      "Epoch 26, CIFAR-10 Batch 4:  Loss:     0.1642 Validation Accuracy: 0.513800 Train Accuracy: 1.000000\n",
      "Epoch 26, CIFAR-10 Batch 5:  Loss:     0.1134 Validation Accuracy: 0.507800 Train Accuracy: 1.000000\n",
      "Epoch 27, CIFAR-10 Batch 1:  Loss:     0.3097 Validation Accuracy: 0.491400 Train Accuracy: 0.950000\n",
      "Epoch 27, CIFAR-10 Batch 2:  Loss:     0.1856 Validation Accuracy: 0.499800 Train Accuracy: 0.975000\n",
      "Epoch 27, CIFAR-10 Batch 3:  Loss:     0.1284 Validation Accuracy: 0.495800 Train Accuracy: 1.000000\n",
      "Epoch 27, CIFAR-10 Batch 4:  Loss:     0.1317 Validation Accuracy: 0.512000 Train Accuracy: 1.000000\n",
      "Epoch 27, CIFAR-10 Batch 5:  Loss:     0.1119 Validation Accuracy: 0.497200 Train Accuracy: 1.000000\n",
      "Epoch 28, CIFAR-10 Batch 1:  Loss:     0.2677 Validation Accuracy: 0.485800 Train Accuracy: 0.950000\n",
      "Epoch 28, CIFAR-10 Batch 2:  Loss:     0.1941 Validation Accuracy: 0.508200 Train Accuracy: 1.000000\n",
      "Epoch 28, CIFAR-10 Batch 3:  Loss:     0.1169 Validation Accuracy: 0.505600 Train Accuracy: 0.975000\n",
      "Epoch 28, CIFAR-10 Batch 4:  Loss:     0.1740 Validation Accuracy: 0.514400 Train Accuracy: 0.975000\n",
      "Epoch 28, CIFAR-10 Batch 5:  Loss:     0.1575 Validation Accuracy: 0.487000 Train Accuracy: 1.000000\n",
      "Epoch 29, CIFAR-10 Batch 1:  Loss:     0.2251 Validation Accuracy: 0.511600 Train Accuracy: 0.950000\n",
      "Epoch 29, CIFAR-10 Batch 2:  Loss:     0.1885 Validation Accuracy: 0.510400 Train Accuracy: 0.975000\n",
      "Epoch 29, CIFAR-10 Batch 3:  Loss:     0.0678 Validation Accuracy: 0.497600 Train Accuracy: 1.000000\n",
      "Epoch 29, CIFAR-10 Batch 4:  Loss:     0.1650 Validation Accuracy: 0.493600 Train Accuracy: 0.975000\n",
      "Epoch 29, CIFAR-10 Batch 5:  Loss:     0.0939 Validation Accuracy: 0.506600 Train Accuracy: 1.000000\n",
      "Epoch 30, CIFAR-10 Batch 1:  Loss:     0.2230 Validation Accuracy: 0.510400 Train Accuracy: 0.950000\n",
      "Epoch 30, CIFAR-10 Batch 2:  Loss:     0.1616 Validation Accuracy: 0.516200 Train Accuracy: 1.000000\n",
      "Epoch 30, CIFAR-10 Batch 3:  Loss:     0.0488 Validation Accuracy: 0.518400 Train Accuracy: 1.000000\n",
      "Epoch 30, CIFAR-10 Batch 4:  Loss:     0.1061 Validation Accuracy: 0.496000 Train Accuracy: 1.000000\n",
      "Epoch 30, CIFAR-10 Batch 5:  Loss:     0.0913 Validation Accuracy: 0.520400 Train Accuracy: 1.000000\n",
      "Epoch 31, CIFAR-10 Batch 1:  Loss:     0.1826 Validation Accuracy: 0.499200 Train Accuracy: 0.975000\n",
      "Epoch 31, CIFAR-10 Batch 2:  Loss:     0.1112 Validation Accuracy: 0.509200 Train Accuracy: 0.975000\n",
      "Epoch 31, CIFAR-10 Batch 3:  Loss:     0.0535 Validation Accuracy: 0.504800 Train Accuracy: 1.000000\n",
      "Epoch 31, CIFAR-10 Batch 4:  Loss:     0.0964 Validation Accuracy: 0.493000 Train Accuracy: 1.000000\n",
      "Epoch 31, CIFAR-10 Batch 5:  Loss:     0.0983 Validation Accuracy: 0.513600 Train Accuracy: 1.000000\n",
      "Epoch 32, CIFAR-10 Batch 1:  Loss:     0.1657 Validation Accuracy: 0.482600 Train Accuracy: 0.975000\n",
      "Epoch 32, CIFAR-10 Batch 2:  Loss:     0.1603 Validation Accuracy: 0.505800 Train Accuracy: 1.000000\n",
      "Epoch 32, CIFAR-10 Batch 3:  Loss:     0.0406 Validation Accuracy: 0.511200 Train Accuracy: 1.000000\n",
      "Epoch 32, CIFAR-10 Batch 4:  Loss:     0.1026 Validation Accuracy: 0.496600 Train Accuracy: 1.000000\n",
      "Epoch 32, CIFAR-10 Batch 5:  Loss:     0.0766 Validation Accuracy: 0.527000 Train Accuracy: 1.000000\n",
      "Epoch 33, CIFAR-10 Batch 1:  Loss:     0.2179 Validation Accuracy: 0.495600 Train Accuracy: 0.975000\n",
      "Epoch 33, CIFAR-10 Batch 2:  Loss:     0.1661 Validation Accuracy: 0.506200 Train Accuracy: 1.000000\n",
      "Epoch 33, CIFAR-10 Batch 3:  Loss:     0.0647 Validation Accuracy: 0.509800 Train Accuracy: 1.000000\n",
      "Epoch 33, CIFAR-10 Batch 4:  Loss:     0.1017 Validation Accuracy: 0.499200 Train Accuracy: 1.000000\n",
      "Epoch 33, CIFAR-10 Batch 5:  Loss:     0.0886 Validation Accuracy: 0.503400 Train Accuracy: 1.000000\n",
      "Epoch 34, CIFAR-10 Batch 1:  Loss:     0.1949 Validation Accuracy: 0.481800 Train Accuracy: 0.950000\n",
      "Epoch 34, CIFAR-10 Batch 2:  Loss:     0.1852 Validation Accuracy: 0.512600 Train Accuracy: 1.000000\n",
      "Epoch 34, CIFAR-10 Batch 3:  Loss:     0.0621 Validation Accuracy: 0.504200 Train Accuracy: 0.975000\n",
      "Epoch 34, CIFAR-10 Batch 4:  Loss:     0.1190 Validation Accuracy: 0.498200 Train Accuracy: 1.000000\n",
      "Epoch 34, CIFAR-10 Batch 5:  Loss:     0.1005 Validation Accuracy: 0.508800 Train Accuracy: 1.000000\n",
      "Epoch 35, CIFAR-10 Batch 1:  Loss:     0.1627 Validation Accuracy: 0.495000 Train Accuracy: 0.950000\n",
      "Epoch 35, CIFAR-10 Batch 2:  Loss:     0.1466 Validation Accuracy: 0.525200 Train Accuracy: 0.950000\n",
      "Epoch 35, CIFAR-10 Batch 3:  Loss:     0.0654 Validation Accuracy: 0.509400 Train Accuracy: 1.000000\n",
      "Epoch 35, CIFAR-10 Batch 4:  Loss:     0.1184 Validation Accuracy: 0.490800 Train Accuracy: 1.000000\n",
      "Epoch 35, CIFAR-10 Batch 5:  Loss:     0.0611 Validation Accuracy: 0.501600 Train Accuracy: 1.000000\n",
      "Epoch 36, CIFAR-10 Batch 1:  Loss:     0.1567 Validation Accuracy: 0.494000 Train Accuracy: 0.975000\n",
      "Epoch 36, CIFAR-10 Batch 2:  Loss:     0.1557 Validation Accuracy: 0.527600 Train Accuracy: 0.975000\n",
      "Epoch 36, CIFAR-10 Batch 3:  Loss:     0.0698 Validation Accuracy: 0.483800 Train Accuracy: 1.000000\n",
      "Epoch 36, CIFAR-10 Batch 4:  Loss:     0.1375 Validation Accuracy: 0.497400 Train Accuracy: 0.975000\n",
      "Epoch 36, CIFAR-10 Batch 5:  Loss:     0.0664 Validation Accuracy: 0.502000 Train Accuracy: 1.000000\n",
      "Epoch 37, CIFAR-10 Batch 1:  Loss:     0.1067 Validation Accuracy: 0.491400 Train Accuracy: 0.975000\n",
      "Epoch 37, CIFAR-10 Batch 2:  Loss:     0.1100 Validation Accuracy: 0.517200 Train Accuracy: 1.000000\n",
      "Epoch 37, CIFAR-10 Batch 3:  Loss:     0.0869 Validation Accuracy: 0.508600 Train Accuracy: 1.000000\n",
      "Epoch 37, CIFAR-10 Batch 4:  Loss:     0.0941 Validation Accuracy: 0.498200 Train Accuracy: 1.000000\n",
      "Epoch 37, CIFAR-10 Batch 5:  Loss:     0.0613 Validation Accuracy: 0.496600 Train Accuracy: 1.000000\n",
      "Epoch 38, CIFAR-10 Batch 1:  Loss:     0.1214 Validation Accuracy: 0.491800 Train Accuracy: 0.975000\n",
      "Epoch 38, CIFAR-10 Batch 2:  Loss:     0.1023 Validation Accuracy: 0.514200 Train Accuracy: 1.000000\n",
      "Epoch 38, CIFAR-10 Batch 3:  Loss:     0.0505 Validation Accuracy: 0.499400 Train Accuracy: 1.000000\n",
      "Epoch 38, CIFAR-10 Batch 4:  Loss:     0.0599 Validation Accuracy: 0.491400 Train Accuracy: 1.000000\n",
      "Epoch 38, CIFAR-10 Batch 5:  Loss:     0.0543 Validation Accuracy: 0.506400 Train Accuracy: 1.000000\n",
      "Epoch 39, CIFAR-10 Batch 1:  Loss:     0.1077 Validation Accuracy: 0.499000 Train Accuracy: 0.975000\n",
      "Epoch 39, CIFAR-10 Batch 2:  Loss:     0.1038 Validation Accuracy: 0.505200 Train Accuracy: 1.000000\n",
      "Epoch 39, CIFAR-10 Batch 3:  Loss:     0.0491 Validation Accuracy: 0.498200 Train Accuracy: 1.000000\n",
      "Epoch 39, CIFAR-10 Batch 4:  Loss:     0.0895 Validation Accuracy: 0.501200 Train Accuracy: 1.000000\n",
      "Epoch 39, CIFAR-10 Batch 5:  Loss:     0.0494 Validation Accuracy: 0.512200 Train Accuracy: 1.000000\n",
      "Epoch 40, CIFAR-10 Batch 1:  Loss:     0.0912 Validation Accuracy: 0.496600 Train Accuracy: 0.975000\n",
      "Epoch 40, CIFAR-10 Batch 2:  Loss:     0.1180 Validation Accuracy: 0.501000 Train Accuracy: 0.975000\n",
      "Epoch 40, CIFAR-10 Batch 3:  Loss:     0.0631 Validation Accuracy: 0.493000 Train Accuracy: 1.000000\n",
      "Epoch 40, CIFAR-10 Batch 4:  Loss:     0.1085 Validation Accuracy: 0.494600 Train Accuracy: 0.950000\n",
      "Epoch 40, CIFAR-10 Batch 5:  Loss:     0.0286 Validation Accuracy: 0.506600 Train Accuracy: 1.000000\n",
      "Epoch 41, CIFAR-10 Batch 1:  Loss:     0.1100 Validation Accuracy: 0.489600 Train Accuracy: 0.975000\n",
      "Epoch 41, CIFAR-10 Batch 2:  Loss:     0.0966 Validation Accuracy: 0.508600 Train Accuracy: 1.000000\n",
      "Epoch 41, CIFAR-10 Batch 3:  Loss:     0.0303 Validation Accuracy: 0.499200 Train Accuracy: 1.000000\n",
      "Epoch 41, CIFAR-10 Batch 4:  Loss:     0.1144 Validation Accuracy: 0.493600 Train Accuracy: 1.000000\n",
      "Epoch 41, CIFAR-10 Batch 5:  Loss:     0.0324 Validation Accuracy: 0.508800 Train Accuracy: 1.000000\n",
      "Epoch 42, CIFAR-10 Batch 1:  Loss:     0.0823 Validation Accuracy: 0.500400 Train Accuracy: 0.975000\n",
      "Epoch 42, CIFAR-10 Batch 2:  Loss:     0.0791 Validation Accuracy: 0.497000 Train Accuracy: 1.000000\n",
      "Epoch 42, CIFAR-10 Batch 3:  Loss:     0.0498 Validation Accuracy: 0.505000 Train Accuracy: 1.000000\n",
      "Epoch 42, CIFAR-10 Batch 4:  Loss:     0.0900 Validation Accuracy: 0.491400 Train Accuracy: 1.000000\n",
      "Epoch 42, CIFAR-10 Batch 5:  Loss:     0.0377 Validation Accuracy: 0.509600 Train Accuracy: 1.000000\n",
      "Epoch 43, CIFAR-10 Batch 1:  Loss:     0.0930 Validation Accuracy: 0.493600 Train Accuracy: 1.000000\n",
      "Epoch 43, CIFAR-10 Batch 2:  Loss:     0.0890 Validation Accuracy: 0.505600 Train Accuracy: 0.975000\n",
      "Epoch 43, CIFAR-10 Batch 3:  Loss:     0.0218 Validation Accuracy: 0.508000 Train Accuracy: 1.000000\n",
      "Epoch 43, CIFAR-10 Batch 4:  Loss:     0.1080 Validation Accuracy: 0.507400 Train Accuracy: 1.000000\n",
      "Epoch 43, CIFAR-10 Batch 5:  Loss:     0.0373 Validation Accuracy: 0.519200 Train Accuracy: 1.000000\n",
      "Epoch 44, CIFAR-10 Batch 1:  Loss:     0.0811 Validation Accuracy: 0.483400 Train Accuracy: 0.950000\n",
      "Epoch 44, CIFAR-10 Batch 2:  Loss:     0.0793 Validation Accuracy: 0.503200 Train Accuracy: 1.000000\n",
      "Epoch 44, CIFAR-10 Batch 3:  Loss:     0.0128 Validation Accuracy: 0.506200 Train Accuracy: 1.000000\n",
      "Epoch 44, CIFAR-10 Batch 4:  Loss:     0.0656 Validation Accuracy: 0.487400 Train Accuracy: 1.000000\n",
      "Epoch 44, CIFAR-10 Batch 5:  Loss:     0.0310 Validation Accuracy: 0.512400 Train Accuracy: 1.000000\n",
      "Epoch 45, CIFAR-10 Batch 1:  Loss:     0.0754 Validation Accuracy: 0.483200 Train Accuracy: 1.000000\n",
      "Epoch 45, CIFAR-10 Batch 2:  Loss:     0.0877 Validation Accuracy: 0.499600 Train Accuracy: 1.000000\n",
      "Epoch 45, CIFAR-10 Batch 3:  Loss:     0.0154 Validation Accuracy: 0.501600 Train Accuracy: 1.000000\n",
      "Epoch 45, CIFAR-10 Batch 4:  Loss:     0.1046 Validation Accuracy: 0.490400 Train Accuracy: 0.975000\n",
      "Epoch 45, CIFAR-10 Batch 5:  Loss:     0.0555 Validation Accuracy: 0.510400 Train Accuracy: 1.000000\n",
      "Epoch 46, CIFAR-10 Batch 1:  Loss:     0.0954 Validation Accuracy: 0.481000 Train Accuracy: 0.975000\n",
      "Epoch 46, CIFAR-10 Batch 2:  Loss:     0.0737 Validation Accuracy: 0.510600 Train Accuracy: 1.000000\n",
      "Epoch 46, CIFAR-10 Batch 3:  Loss:     0.0150 Validation Accuracy: 0.510400 Train Accuracy: 1.000000\n",
      "Epoch 46, CIFAR-10 Batch 4:  Loss:     0.0639 Validation Accuracy: 0.488400 Train Accuracy: 0.975000\n",
      "Epoch 46, CIFAR-10 Batch 5:  Loss:     0.0322 Validation Accuracy: 0.507400 Train Accuracy: 1.000000\n",
      "Epoch 47, CIFAR-10 Batch 1:  Loss:     0.0524 Validation Accuracy: 0.474000 Train Accuracy: 1.000000\n",
      "Epoch 47, CIFAR-10 Batch 2:  Loss:     0.0538 Validation Accuracy: 0.510200 Train Accuracy: 1.000000\n",
      "Epoch 47, CIFAR-10 Batch 3:  Loss:     0.0084 Validation Accuracy: 0.516600 Train Accuracy: 1.000000\n",
      "Epoch 47, CIFAR-10 Batch 4:  Loss:     0.0691 Validation Accuracy: 0.499800 Train Accuracy: 0.975000\n",
      "Epoch 47, CIFAR-10 Batch 5:  Loss:     0.0280 Validation Accuracy: 0.508800 Train Accuracy: 1.000000\n",
      "Epoch 48, CIFAR-10 Batch 1:  Loss:     0.0421 Validation Accuracy: 0.495600 Train Accuracy: 1.000000\n",
      "Epoch 48, CIFAR-10 Batch 2:  Loss:     0.0337 Validation Accuracy: 0.510600 Train Accuracy: 1.000000\n",
      "Epoch 48, CIFAR-10 Batch 3:  Loss:     0.0148 Validation Accuracy: 0.522800 Train Accuracy: 1.000000\n",
      "Epoch 48, CIFAR-10 Batch 4:  Loss:     0.0694 Validation Accuracy: 0.505000 Train Accuracy: 1.000000\n",
      "Epoch 48, CIFAR-10 Batch 5:  Loss:     0.0637 Validation Accuracy: 0.515800 Train Accuracy: 1.000000\n",
      "Epoch 49, CIFAR-10 Batch 1:  Loss:     0.0504 Validation Accuracy: 0.485600 Train Accuracy: 1.000000\n",
      "Epoch 49, CIFAR-10 Batch 2:  Loss:     0.0481 Validation Accuracy: 0.511800 Train Accuracy: 1.000000\n",
      "Epoch 49, CIFAR-10 Batch 3:  Loss:     0.0362 Validation Accuracy: 0.505800 Train Accuracy: 1.000000\n",
      "Epoch 49, CIFAR-10 Batch 4:  Loss:     0.0713 Validation Accuracy: 0.503600 Train Accuracy: 1.000000\n",
      "Epoch 49, CIFAR-10 Batch 5:  Loss:     0.0488 Validation Accuracy: 0.517200 Train Accuracy: 1.000000\n",
      "Epoch 50, CIFAR-10 Batch 1:  Loss:     0.0624 Validation Accuracy: 0.490400 Train Accuracy: 1.000000\n",
      "Epoch 50, CIFAR-10 Batch 2:  Loss:     0.0736 Validation Accuracy: 0.509200 Train Accuracy: 1.000000\n",
      "Epoch 50, CIFAR-10 Batch 3:  Loss:     0.0387 Validation Accuracy: 0.509000 Train Accuracy: 1.000000\n",
      "Epoch 50, CIFAR-10 Batch 4:  Loss:     0.0530 Validation Accuracy: 0.510000 Train Accuracy: 1.000000\n",
      "Epoch 50, CIFAR-10 Batch 5:  Loss:     0.0327 Validation Accuracy: 0.509000 Train Accuracy: 1.000000\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "save_model_path = './image_classification'\n",
    "\n",
    "print('Training...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        # Loop over all batches\n",
    "        n_batches = 5\n",
    "        for batch_i in range(1, n_batches + 1):\n",
    "            for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "                train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "            print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "            print_stats(sess, batch_features, batch_labels, cost, accuracy)\n",
    "            \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Checkpoint\n",
    "The model has been saved to disk.\n",
    "## Test Model\n",
    "Test your model against the test dataset.  This will be your final accuracy. You should have an accuracy greater than 50%. If you don't, keep tweaking the model architecture and parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 0.5142578125\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAscAAAJ/CAYAAACUb342AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEREREZHo/wPNWpjpm21pJAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc8ffdc43c8>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 319,
       "width": 355
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import helper\n",
    "import random\n",
    "\n",
    "# Set batch size if not already set\n",
    "try:\n",
    "    if batch_size:\n",
    "        pass\n",
    "except NameError:\n",
    "    batch_size = 64\n",
    "\n",
    "save_model_path = './image_classification'\n",
    "n_samples = 4\n",
    "top_n_predictions = 3\n",
    "\n",
    "def test_model():\n",
    "    \"\"\"\n",
    "    Test the saved model against the test dataset\n",
    "    \"\"\"\n",
    "\n",
    "    test_features, test_labels = pickle.load(open('preprocess_test.p', mode='rb'))\n",
    "    loaded_graph = tf.Graph()\n",
    "\n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        # Load model\n",
    "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "        loader.restore(sess, save_model_path)\n",
    "\n",
    "        # Get Tensors from loaded model\n",
    "        loaded_x = loaded_graph.get_tensor_by_name('x:0')\n",
    "        loaded_y = loaded_graph.get_tensor_by_name('y:0')\n",
    "        loaded_keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "        loaded_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "        loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
    "        \n",
    "        # Get accuracy in batches for memory limitations\n",
    "        test_batch_acc_total = 0\n",
    "        test_batch_count = 0\n",
    "        \n",
    "        for test_feature_batch, test_label_batch in helper.batch_features_labels(test_features, test_labels, batch_size):\n",
    "            test_batch_acc_total += sess.run(\n",
    "                loaded_acc,\n",
    "                feed_dict={loaded_x: test_feature_batch, loaded_y: test_label_batch, loaded_keep_prob: 1.0})\n",
    "            test_batch_count += 1\n",
    "\n",
    "        print('Testing Accuracy: {}\\n'.format(test_batch_acc_total/test_batch_count))\n",
    "\n",
    "        # Print Random Samples\n",
    "        random_test_features, random_test_labels = tuple(zip(*random.sample(list(zip(test_features, test_labels)), n_samples)))\n",
    "        random_test_predictions = sess.run(\n",
    "            tf.nn.top_k(tf.nn.softmax(loaded_logits), top_n_predictions),\n",
    "            feed_dict={loaded_x: random_test_features, loaded_y: random_test_labels, loaded_keep_prob: 1.0})\n",
    "        helper.display_image_predictions(random_test_features, random_test_labels, random_test_predictions)\n",
    "\n",
    "\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Why 50-80% Accuracy?\n",
    "You might be wondering why you can't get an accuracy any higher. First things first, 50% isn't bad for a simple CNN.  Pure guessing would get you 10% accuracy. However, you might notice people are getting scores [well above 80%](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#43494641522d3130).  That's because we haven't taught you all there is to know about neural networks. We still need to cover a few more techniques.\n",
    "## Submitting This Project\n",
    "When submitting this project, make sure to run all the cells before saving the notebook.  Save the notebook file as \"dlnd_image_classification.ipynb\" and save it as a HTML file under \"File\" -> \"Download as\".  Include the \"helper.py\" and \"problem_unittests.py\" files in your submission."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
